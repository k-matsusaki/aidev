{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xu0GaP80H0M"
      },
      "source": [
        "# 課題5：映画レビューの評判分析\n",
        "\n",
        "本課題ではAmazon傘下の「IMDb」に投稿された映画のレビュー（英語）を分析し、レビューがPositive（ポジティブ）か、Negative（ネガティブ）かの判別を行ないます。\n",
        "\n",
        "データセットは、以下のサイトで配布されているものを利用します。\n",
        "\n",
        "[Large Movie Review Dataset](https://ai.stanford.edu/%7Eamaas/data/sentiment/)\n",
        "\n",
        "わからない場合は、ここまでのレッスン内容や各種ライブラリの公式ドキュメントを参照しましょう。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnNp3e4X1VzH"
      },
      "source": [
        "## 1. 必要なライブラリのimport"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "NzALkNahz3So"
      },
      "outputs": [],
      "source": [
        "# （変更しないでください）\n",
        "\n",
        "# 必要なライブラリのimport\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# 文章ファイル検索用\n",
        "import glob\n",
        "import collections\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "\n",
        "# DataFrameですべての列を表示する設定\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "# seabornによる装飾を適用する\n",
        "sns.set_theme()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3pjMa-V1j3i"
      },
      "source": [
        "## 2. データの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "O7uOIUKE46-c"
      },
      "outputs": [],
      "source": [
        "# ダウンロードした圧縮ファイルを解凍する（変更しないでください）\n",
        "#!tar zxvf aclImdb_v1.tar.gz\n",
        "\n",
        "#時間がかかりすぎたため、解凍したフォルダをアップロードしました"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiKcOmlbJQ1r"
      },
      "source": [
        "*./aclImdb* フォルダ内にあるファイルを読み込みます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "hSQxdWMe5Dpm"
      },
      "outputs": [],
      "source": [
        "# trainフォルダのファイル一覧を取得（変更しないでください）\n",
        "train_neg_files = glob.glob(\"./aclImdb/train/neg/*\")\n",
        "train_pos_files = glob.glob(\"./aclImdb/train/pos/*\")\n",
        "\n",
        "# testフォルダのファイル一覧を取得（変更しないでください）\n",
        "test_neg_files = glob.glob(\"./aclImdb/test/neg/*\")\n",
        "test_pos_files = glob.glob(\"./aclImdb/test/pos/*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "AwILbT3E3uRu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "12500\n",
            "12500\n",
            "12500\n",
            "12500\n"
          ]
        }
      ],
      "source": [
        "# それぞれのファイル数を確認\n",
        "print(len(train_neg_files))\n",
        "print(len(train_pos_files))\n",
        "print(len(test_neg_files))\n",
        "print(len(test_pos_files))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOezW34ZJfwA"
      },
      "source": [
        "前処理をするため、合計50000あるファイルをリストにまとめます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "8PJps6pk5xP1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ファイル名をまとめたリストを用意（変更しないでください）\n",
        "filenames = train_neg_files + train_pos_files + test_neg_files + test_pos_files\n",
        "\n",
        "# filenamesの長さを確認（変更しないでください）\n",
        "len(filenames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOVm-xBvJuQd"
      },
      "source": [
        "リストの最初と最後のファイルを確認してみます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "D10DLJRv5y2d"
      },
      "outputs": [],
      "source": [
        "# エンコーディング用定数（変更しないでください）\n",
        "ENCODING = 'utf-8'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "tR1blqz-6ytX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How they got Al Pacino to play in this movie is beyond me. This movie is absolutely terrible. I discovered, after reading some of the other reviews, that a couple of people actually enjoyed this film, which deeply puzzles me, because I do not see how anyone in their right mind could possibly enjoy a movie as awful as Revolution. It's not just that it's a bad movie, with a lame plot and overall strangeness that is extremely unpleasant, but it seems as if the filmmakers were either mentally retarded (which is a very possible explanation as to why this movie sucks like it does, though it probably still sucks even compared to other films made by retards) or deliberately made every illogical decision to make this movie suck as much as possible. For example, we see Donald Sutherland running around with a huge, fat ugly mole on his face. He does not normally have a mole. The mole does not add to his character. It is extremely ugly and distracting. It's not like Robert De Niro's mole; it's much worse. Why the hell has he got that mole? It's as if the filmmakers just said, \"Let's see, how could we make this movie even worse than it already is? I know, let's give Mr. Sutherland a giant, ugly-ass mole right on his face.\"<br /><br />Another example of the filmmakers' stupidity is the character Ned. We see, for the first three-quarters of the movie, young Ned. At one point, \"six months later\" appears on the screen. We see Ned again, and it is, of course, the same actor playing the boy. Five minutes later, \"three weeks later\" appears on the screen, and all of a sudden we've got a different actor playing as the now older Ned. What, do they think we're idiots? Good God! Again, it's like the filmmakers are saying, \"How can we possibly make it any worse? I don't think we can...Oh wait! I just had a terrible idea!\" I know a kid doesn't grow much in half a year, which is fine, but he at least grows more than he does in three weeks. Just don't get another actor to play Ned, or at least get him to play the five minutes when he's three weeks younger. Furthermore, the kid who plays the \"older\" Ned does not look any older than \"young\" Ned. As a matter of fact, he just looks completely different, much skinnier, and no taller or older than the original actor, which is very confusing, as I, like any rational human being, thought at first that it was a new and different character.<br /><br />What, did the first kid die while they were filming the movie? Because he was in it for the first hour and a half, and then all of a sudden, three weeks later, the guy from Lock Stock and Two Smoking Barrels is playing Ned for the last five minutes of the movie. And even if the original actor did die, the filmmakers should have at least gotten an actor who looks like him to play the remainder of his role, and re-shoot the measly five minutes of \"six months later\" scenes. Better yet, just scrap the movie completely, never finish it and never release, never even tell anybody about it, because by that point they should have realized that their movie sucks and in finishing it they would only waste more money and time and succeed in making one of the worst movies of all time.<br /><br />I'm not saying that this movie is so bad you shouldn't watch it; it's so bad that you SHOULD watch it, just to see how badly it sucks. It's terrible, terrible.\n"
          ]
        }
      ],
      "source": [
        "# 最初のファイルの内容を確認\n",
        "with open(filenames[0], encoding=ENCODING) as f:\n",
        "    text = f.read()\n",
        "    print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "KrvFZOcc62RQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This is the last film of a trilogy by the brilliant Turkish director, Nuri Bilge Ceylan, whose last film Mayis Sikintisi -which was very Cehovian- was shown in prestigious film festivals. Differing from his previous films, the story of 'Uzak' is set on Istanbul which is one of the most crowded cities of the world. However, in Ceylan's film, we do see only minor traces of that huge crowd. Rather he choose to focus on two characters, one photographer and one of his relatives who comes from his small village to find a job on transatlantic ships. The photographer, who -we understand that- has also immigrated to the city, seems to be inhabited the customs of the city life, not only in material sense. In his relation to his relative, we see him first as caring and tolerant, however, when he could not find a job, our suburbian character starts to be disturbed for sharing his private 'space' with someone whose leaving date becomes ambiguous. I will not reveal the tactics he develops in order to pull his relative out of his life to prevent any harm on your viewing pleasure, but it is enough to say that Ceylan shows us the tactics that we acquire within the routine of suburbian life; 'tactics' to keep our own private space, 'tactics' in order not to communicate with other people, 'tactics' to prevent our relationships from gaining a complex nature (since our own experience, we believe that, is complex enough).<br /><br />Ceylan's film presents a clear picture of what a human being becomes within the borders of modern (or postmodern ?) city by depicting the two characters in different manners. But, he doesn't condemn any of the two characters for doing this, rather he uses the power of cinematic language to underline this difference. For example, in search of new opportunities, we always see the character coming from the village in open spaces. Even within the house, he prefers balcony as his favourite space. On the other hand, we see the photographer always within the closed spaces, and generally at his home. Although there are more than 10 million people out there, and lots of adventures, lots of interesting things to discover (or are there any?) he prefers sitting at home, watching TV, etc. His home is like his temple, a kind of sacred place.<br /><br />Everyone living in a big city, and conscious of the experience he is living through, will find something belonging to himself in Uzak. If you like this film, I am sure that you will like Ceylan's other two films, Mayis Sikintisi (The Clouds of May) and Kasaba (The Town). Go and find them!.\n"
          ]
        }
      ],
      "source": [
        "# 最後のファイルの内容を確認\n",
        "with open(filenames[-1], encoding=ENCODING) as f:\n",
        "    text = f.read()\n",
        "    print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1MSLkqD9o_i"
      },
      "source": [
        "## 3. データの前処理\n",
        "\n",
        "データの前処理として、形態素解析と行列への変換を行ないます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iir0OFu_Xu1"
      },
      "source": [
        "### 形態素解析"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Wai2oEG39jF8"
      },
      "outputs": [],
      "source": [
        "# 文字列の中で使われている単語ごとの数を返す関数を作成\n",
        "#（レッスン本編の内容を確認して、下記にコードを追記してください）\n",
        "def get_word_count(text, min_length=3):\n",
        "    #ノイズ除去\n",
        "    for ch in \".,:;!?-+*/=()[]{}<>~^#$@%&'\\\"_0123456789\":\n",
        "        text = text.replace(ch, ' ')\n",
        "    \n",
        "    #単語に分割\n",
        "    _words = text.strip().split()\n",
        "\n",
        "    #表記ゆれ補正\n",
        "    _words = [word.lower() for word in _words if len(word) >= min_length]\n",
        "    \n",
        "    # collections.Counterの戻り値は辞書型のサブクラス\n",
        "    _count = collections.Counter(_words)\n",
        "\n",
        "    # 辞書型に変換して返す\n",
        "    return dict(_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "5BmIbEf699gs"
      },
      "outputs": [],
      "source": [
        "# 最初のファイルを使って、先ほど作成した関数をテスト\n",
        "with open(filenames[0], 'r', encoding=ENCODING) as f:\n",
        "    text = f.read()\n",
        "\n",
        "    get_word_count(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Sze6ofim-OTR"
      },
      "outputs": [],
      "source": [
        "# 単語ごとの数のリストを作成（変更しないでください）\n",
        "word_count_data = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "bN54gjEh-QKj"
      },
      "outputs": [],
      "source": [
        "# すべてのファイルに対して、先ほど作成した関数を実行\n",
        "for filename in filenames:\n",
        "    with open(filename, 'r', encoding=ENCODING) as f:\n",
        "        text = f.read()\n",
        "        count = get_word_count(text)\n",
        "        word_count_data.append(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "BIIkPnNL-gQP"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 単語ごとの数のリストの長さを確認\n",
        "len(word_count_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "DZGy0O5F-gje"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'how': 5,\n",
              " 'they': 5,\n",
              " 'got': 3,\n",
              " 'pacino': 1,\n",
              " 'play': 4,\n",
              " 'this': 7,\n",
              " 'movie': 13,\n",
              " 'beyond': 1,\n",
              " 'absolutely': 1,\n",
              " 'terrible': 4,\n",
              " 'discovered': 1,\n",
              " 'after': 1,\n",
              " 'reading': 1,\n",
              " 'some': 1,\n",
              " 'the': 31,\n",
              " 'other': 2,\n",
              " 'reviews': 1,\n",
              " 'that': 9,\n",
              " 'couple': 1,\n",
              " 'people': 1,\n",
              " 'actually': 1,\n",
              " 'enjoyed': 1,\n",
              " 'film': 1,\n",
              " 'which': 4,\n",
              " 'deeply': 1,\n",
              " 'puzzles': 1,\n",
              " 'because': 3,\n",
              " 'not': 7,\n",
              " 'see': 6,\n",
              " 'anyone': 1,\n",
              " 'their': 2,\n",
              " 'right': 2,\n",
              " 'mind': 1,\n",
              " 'could': 2,\n",
              " 'possibly': 2,\n",
              " 'enjoy': 1,\n",
              " 'awful': 1,\n",
              " 'revolution': 1,\n",
              " 'just': 7,\n",
              " 'bad': 3,\n",
              " 'with': 2,\n",
              " 'lame': 1,\n",
              " 'plot': 1,\n",
              " 'and': 15,\n",
              " 'overall': 1,\n",
              " 'strangeness': 1,\n",
              " 'extremely': 2,\n",
              " 'unpleasant': 1,\n",
              " 'but': 2,\n",
              " 'seems': 1,\n",
              " 'filmmakers': 5,\n",
              " 'were': 2,\n",
              " 'either': 1,\n",
              " 'mentally': 1,\n",
              " 'retarded': 1,\n",
              " 'very': 2,\n",
              " 'possible': 2,\n",
              " 'explanation': 1,\n",
              " 'why': 2,\n",
              " 'sucks': 4,\n",
              " 'like': 5,\n",
              " 'does': 5,\n",
              " 'though': 1,\n",
              " 'probably': 1,\n",
              " 'still': 1,\n",
              " 'even': 4,\n",
              " 'compared': 1,\n",
              " 'films': 1,\n",
              " 'made': 2,\n",
              " 'retards': 1,\n",
              " 'deliberately': 1,\n",
              " 'every': 1,\n",
              " 'illogical': 1,\n",
              " 'decision': 1,\n",
              " 'make': 3,\n",
              " 'suck': 1,\n",
              " 'much': 4,\n",
              " 'for': 4,\n",
              " 'example': 2,\n",
              " 'donald': 1,\n",
              " 'sutherland': 2,\n",
              " 'running': 1,\n",
              " 'around': 1,\n",
              " 'huge': 1,\n",
              " 'fat': 1,\n",
              " 'ugly': 3,\n",
              " 'mole': 6,\n",
              " 'his': 4,\n",
              " 'face': 2,\n",
              " 'normally': 1,\n",
              " 'have': 3,\n",
              " 'add': 1,\n",
              " 'character': 3,\n",
              " 'distracting': 1,\n",
              " 'robert': 1,\n",
              " 'niro': 1,\n",
              " 'worse': 3,\n",
              " 'hell': 1,\n",
              " 'has': 1,\n",
              " 'said': 1,\n",
              " 'let': 2,\n",
              " 'than': 4,\n",
              " 'already': 1,\n",
              " 'know': 2,\n",
              " 'give': 1,\n",
              " 'giant': 1,\n",
              " 'ass': 1,\n",
              " 'another': 2,\n",
              " 'stupidity': 1,\n",
              " 'ned': 8,\n",
              " 'first': 4,\n",
              " 'three': 5,\n",
              " 'quarters': 1,\n",
              " 'young': 2,\n",
              " 'one': 2,\n",
              " 'point': 2,\n",
              " 'six': 2,\n",
              " 'months': 2,\n",
              " 'later': 5,\n",
              " 'appears': 2,\n",
              " 'screen': 2,\n",
              " 'again': 2,\n",
              " 'course': 1,\n",
              " 'same': 1,\n",
              " 'actor': 6,\n",
              " 'playing': 3,\n",
              " 'boy': 1,\n",
              " 'five': 4,\n",
              " 'minutes': 4,\n",
              " 'weeks': 4,\n",
              " 'all': 3,\n",
              " 'sudden': 2,\n",
              " 'different': 3,\n",
              " 'now': 1,\n",
              " 'older': 4,\n",
              " 'what': 2,\n",
              " 'think': 2,\n",
              " 'idiots': 1,\n",
              " 'good': 1,\n",
              " 'god': 1,\n",
              " 'are': 1,\n",
              " 'saying': 2,\n",
              " 'can': 2,\n",
              " 'any': 3,\n",
              " 'don': 2,\n",
              " 'wait': 1,\n",
              " 'had': 1,\n",
              " 'idea': 1,\n",
              " 'kid': 3,\n",
              " 'doesn': 1,\n",
              " 'grow': 1,\n",
              " 'half': 2,\n",
              " 'year': 1,\n",
              " 'fine': 1,\n",
              " 'least': 3,\n",
              " 'grows': 1,\n",
              " 'more': 2,\n",
              " 'get': 2,\n",
              " 'him': 2,\n",
              " 'when': 1,\n",
              " 'younger': 1,\n",
              " 'furthermore': 1,\n",
              " 'who': 2,\n",
              " 'plays': 1,\n",
              " 'look': 1,\n",
              " 'matter': 1,\n",
              " 'fact': 1,\n",
              " 'looks': 2,\n",
              " 'completely': 2,\n",
              " 'skinnier': 1,\n",
              " 'taller': 1,\n",
              " 'original': 2,\n",
              " 'confusing': 1,\n",
              " 'rational': 1,\n",
              " 'human': 1,\n",
              " 'being': 1,\n",
              " 'thought': 1,\n",
              " 'was': 2,\n",
              " 'new': 1,\n",
              " 'did': 2,\n",
              " 'die': 2,\n",
              " 'while': 1,\n",
              " 'filming': 1,\n",
              " 'hour': 1,\n",
              " 'then': 1,\n",
              " 'guy': 1,\n",
              " 'from': 1,\n",
              " 'lock': 1,\n",
              " 'stock': 1,\n",
              " 'two': 1,\n",
              " 'smoking': 1,\n",
              " 'barrels': 1,\n",
              " 'last': 1,\n",
              " 'should': 3,\n",
              " 'gotten': 1,\n",
              " 'remainder': 1,\n",
              " 'role': 1,\n",
              " 'shoot': 1,\n",
              " 'measly': 1,\n",
              " 'scenes': 1,\n",
              " 'better': 1,\n",
              " 'yet': 1,\n",
              " 'scrap': 1,\n",
              " 'never': 3,\n",
              " 'finish': 1,\n",
              " 'release': 1,\n",
              " 'tell': 1,\n",
              " 'anybody': 1,\n",
              " 'about': 1,\n",
              " 'realized': 1,\n",
              " 'finishing': 1,\n",
              " 'would': 1,\n",
              " 'only': 1,\n",
              " 'waste': 1,\n",
              " 'money': 1,\n",
              " 'time': 2,\n",
              " 'succeed': 1,\n",
              " 'making': 1,\n",
              " 'worst': 1,\n",
              " 'movies': 1,\n",
              " 'you': 2,\n",
              " 'shouldn': 1,\n",
              " 'watch': 2,\n",
              " 'badly': 1}"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 単語ごとの数のリストの0番目を表示\n",
        "word_count_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8NZjYT0_aLX"
      },
      "source": [
        "### 行列への変換"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "LTWbRq4T_bNO"
      },
      "outputs": [],
      "source": [
        "# DictVectorizerを使用して行列に変換し、datasetに格納する\n",
        "vec = DictVectorizer()\n",
        "dataset = vec.fit_transform(word_count_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "jeeGumr4_fT5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 101249)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# datasetの大きさを確認\n",
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "kCvgn5UW_i2Y"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['\\x08\\x08\\x08\\x08a', '\\x10own', '\\\\and\\\\', ..., '…although',\n",
              "       '…but', '…until'], dtype=object)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 各列に対応した単語を取得\n",
        "vec.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nc7Xp8D_xC2"
      },
      "source": [
        "## 4. 機械学習の実施"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "JoLhZFvz_mSo"
      },
      "outputs": [],
      "source": [
        "# 必要なライブラリの追加import（変更しないでください）\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_f5_xO8_KDje"
      },
      "source": [
        "目的変数と説明変数を用意します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "le7zEl0BIxWr"
      },
      "outputs": [],
      "source": [
        "# 目的変数Yの用意\n",
        "# neg12500 + pos12500 + neg12500 + pos12500 = 50000\n",
        "Y = np.array([0]*12500 + [1]*12500 + [0]*12500 + [1]*12500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Jsy8g6L2JHdo"
      },
      "outputs": [],
      "source": [
        "# 上記のY、および前処理されたdatasetからデータを分割し、\n",
        "# X_train, Y_train, X_test, Y_testに格納する\n",
        "#\n",
        "# 詳細：\n",
        "#   - dataset の先頭から25000件を 変数 X_train に、残りを変数 X_test に代入\n",
        "#   - 目的変数 Y の先頭から25000件を 変数 Y_train に、残りを Y_test に代入\n",
        "\n",
        "X_train = dataset[:25000]\n",
        "X_test = dataset[25000:]\n",
        "Y_train = Y[:25000]\n",
        "Y_test = Y[25000:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Z437TWo0Ky5w"
      },
      "outputs": [],
      "source": [
        "# X_trainとY_trainを、train_test_splitで7:3に分割し、3割のほうを検証データ（X_valid, Y_valid）にする\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size=0.3, random_state=0)\n",
        "X_train, X_valid, Y_train, Y_valid = train_test_split(X_train, Y_train, test_size=0.3, random_state=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "c31t4guALPTO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.85      0.86      2609\n",
            "           1       0.86      0.88      0.87      2641\n",
            "\n",
            "    accuracy                           0.87      5250\n",
            "   macro avg       0.87      0.87      0.87      5250\n",
            "weighted avg       0.87      0.87      0.87      5250\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ロジスティック回帰モデルを作成し、学習して、検証データによる予測を実施する\n",
        "Logistic_model = LogisticRegression(max_iter=500)\n",
        "Logistic_model.fit(X_train, Y_train)\n",
        "Y_pred = Logistic_model.predict(X_valid)\n",
        "\n",
        "# classification_reportを実行し、検証データによるモデルの評価を行なう\n",
        "print(classification_report(Y_valid, Y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aiRUHbnM3Ac"
      },
      "source": [
        "## 5. テストデータによる評価\n",
        "\n",
        "最後に、テストデータで評価を行ないましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "kpHmZx8pM3V7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.86      0.87      3767\n",
            "           1       0.86      0.87      0.87      3733\n",
            "\n",
            "    accuracy                           0.87      7500\n",
            "   macro avg       0.87      0.87      0.87      7500\n",
            "weighted avg       0.87      0.87      0.87      7500\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# テストデータで予測を実施する\n",
        "Y_pred = Logistic_model.predict(X_test)\n",
        "\n",
        "# classification_reportを実行し、テストデータによるモデルの評価を行なう\n",
        "print(classification_report(Y_test, Y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
